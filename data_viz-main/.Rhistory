View(data)
View(workinghours)
View(data)
View(workinghours)
View(data)
to_add$group <- rep(levels(data$group), each=empty_bar*nObsType )
data <- data.frame(
individual=paste( "Mister ", seq(1,60), sep=""),
group=c( rep('A', 10), rep('B', 30), rep('C', 14), rep('D', 6)) ,
value1=sample( seq(10,100), 60, replace=T),
value2=sample( seq(10,100), 60, replace=T),
value3=sample( seq(10,100), 60, replace=T)
)
data <- data.frame(
individual=paste( "Mister ", seq(1,60), sep=""),
group=c( rep('A', 10), rep('B', 30), rep('C', 14), rep('D', 6)) ,
value1=sample( seq(10,100), 60, replace=T),
value2=sample( seq(10,100), 60, replace=T),
value3=sample( seq(10,100), 60, replace=T)
)
# Transform data in a tidy format (long format)
data <- data %>% gather(key = "observation", value="value", -c(1,2))
empty_bar <- 2
nObsType <- nlevels(as.factor(data$observation))
to_add <- data.frame( matrix(NA, empty_bar*nlevels(data$group)*nObsType, ncol(data)) )
colnames(to_add) <- colnames(data)
to_add$group <- rep(levels(data$group), each=empty_bar*nObsType )
data <- rbind(data, to_add)
data <- data %>% arrange(group, individual)
data$id <- rep( seq(1, nrow(data)/nObsType) , each=nObsType)
View(data)
View(to_add)
View(data)
data$id <- rep( seq(1, nrow(data)/nObsType) , each=nObsType)
data <- data.frame(
individual=paste( "Mister ", seq(1,60), sep=""),
group=c( rep('A', 10), rep('B', 30), rep('C', 14), rep('D', 6)) ,
value1=sample( seq(10,100), 60, replace=T),
value2=sample( seq(10,100), 60, replace=T),
value3=sample( seq(10,100), 60, replace=T)
)
# Transform data in a tidy format (long format)
data <- data %>% gather(key = "observation", value="value", -c(1,2))
empty_bar <- 2
nObsType <- nlevels(as.factor(data$observation))
to_add <- data.frame( matrix(NA, empty_bar*nlevels(data$group)*nObsType, ncol(data)) )
colnames(to_add) <- colnames(data)
to_add$group <- rep(levels(data$group), each=empty_bar*nObsType )
data <- rbind(data, to_add)
data <- data %>% arrange(group, individual)
data$id <- rep( seq(1, nrow(data)/nObsType) , each=nObsType)
label_data <- data %>% group_by(id, individual) %>% summarize(tot=sum(value))
number_of_bar <- nrow(label_data)
angle <- 90 - 360 * (label_data$id-0.5) /number_of_bar     # I substract 0.5 because the letter must have the angle of the center of the bars. Not extreme right(1) or extreme left (0)
label_data$hjust <- ifelse( angle < -90, 1, 0)
label_data$angle <- ifelse(angle < -90, angle+180, angle)
View(data)
View(label_data)
View(data)
View(to_add)
base_data <- data %>%
group_by(group) %>%
summarize(start=min(id), end=max(id) - empty_bar) %>%
rowwise() %>%
mutate(title=mean(c(start, end)))
View(base_data)
workinghours <- read_csv("./sleep_score.csv")
sleep <- read_csv("./sleep_score.csv")
n
workinghours <- read_csv("./WorkingHours.csv") %>%
mutate(date = mdy(Day),
month = month(date),
year = year(date)) %>%
separate(Duration,c("hour","min"),":") %>%
mutate(hour = as.numeric(hour),
min = as.numeric(min),
duration = hour + min/60) %>%
group_by(Task, month, year) %>%
summarise(hours = round(sum(duration),2))
View(sleep)
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score))
?date()
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(date = date(month,year,1))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates =paste(year,month,1,sep="/"))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates =paste(month,1,year,sep="/"))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates =as.date(paste(month,1,year,sep="/")))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates =ymd(paste(month,1,year,sep="/")))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates = as.date(dates,"m/y"))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates = as.Date(dates,"m/y"))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates = as.Date(dates,"%m/%d/%y"))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates_clean = as.Date(dates,"%m/%d/%y"))
dates_clean = mdy(dates)
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates_clean = mdy(dates))
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates_clean = mdy(dates)) %>%
arrange(month,year)
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
mutate(dates = paste(month,1,year,sep="/"),
dates_clean = mdy(dates)) %>%
arrange(year,month)
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
arrange(year,month)
sleep <- read_csv("./sleep_score.csv") %>%
mutate(month = month(timestamp),
year = year(timestamp)) %>%
group_by(month,year) %>%
summarise(score = mean(overall_score)) %>%
ungroup() %>%
arrange(year,month) %>%
mutate(id = seq(1,14))
p <- ggplot(sleep, aes(x=as.factor(id), y=score)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
# This add the bars with a blue color
geom_bar(stat="identity", fill=alpha("blue", 0.3)) +
# Limits of the plot = very important. The negative value controls the size of the inner circle, the positive one is useful to add size over each bar
ylim(-100,120) +
# Custom the theme: no axis title and no cartesian grid
theme_minimal() +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
panel.grid = element_blank(),
plot.margin = unit(rep(-2,4), "cm")     # This remove unnecessary margin around plot
) +
# This makes the coordinate polar instead of cartesian.
coord_polar(start = 0)
library(ggplot2)
p <- ggplot(sleep, aes(x=as.factor(id), y=score)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
# This add the bars with a blue color
geom_bar(stat="identity", fill=alpha("blue", 0.3)) +
# Limits of the plot = very important. The negative value controls the size of the inner circle, the positive one is useful to add size over each bar
ylim(-100,120) +
# Custom the theme: no axis title and no cartesian grid
theme_minimal() +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
panel.grid = element_blank(),
plot.margin = unit(rep(-2,4), "cm")     # This remove unnecessary margin around plot
) +
# This makes the coordinate polar instead of cartesian.
coord_polar(start = 0)
p
p <- ggplot(sleep, aes(x=as.factor(id), y=score)) +       # Note that id is a factor. If x is numeric, there is some space between the first bar
# This add the bars with a blue color
geom_bar(stat="identity", fill=alpha("blue", 0.3)) +
# Limits of the plot = very important. The negative value controls the size of the inner circle, the positive one is useful to add size over each bar
ylim(-100,140) +
# Custom the theme: no axis title and no cartesian grid
theme_minimal() +
theme(
axis.text = element_blank(),
axis.title = element_blank(),
panel.grid = element_blank(),
plot.margin = unit(rep(-2,4), "cm")     # This remove unnecessary margin around plot
) +
# This makes the coordinate polar instead of cartesian.
coord_polar(start = 0)
p
View(data)
library(sf)
library(sf,readr)
storefronts <- read_csv("./Downloads/Storefronts_Reported_Vacant_or_Not.csv")
library(sf,readr)
storefronts <- read_csv("./Downloads/Storefronts_Reported_Vacant_or_Not.csv")
library(readr)
storefronts <- read_csv("./Downloads/Storefronts_Reported_Vacant_or_Not.csv")
storefronts <- read_csv("./Desktop/Storefronts_Reported_Vacant_or_Not.csv")
names(storefronts)
storefronts_sf <- st_as_sf(storefronts,coords = c("LATITUDE","LONGITUDE"))
?st_as_sf
storefronts <- read_csv("./Desktop/Storefronts_Reported_Vacant_or_Not.csv") %>%
remove_na()
library(dplyr)
?remove_na
??remove_na
storefronts <- read_csv("./Desktop/Storefronts_Reported_Vacant_or_Not.csv") %>%
na.omit()
storefronts <- read_csv("./Desktop/Storefronts_Reported_Vacant_or_Not.csv",na = NA)
storefronts <- read_csv("./Desktop/Storefronts_Reported_Vacant_or_Not.csv") %>%
filter(!is.na(LATITUDE))
storefronts <- read_csv("./Desktop/Storefronts_Reported_Vacant_or_Not.csv") %>%
filter(!is.na(LATITUDE),
!is.na(LONGITUDE))
storefronts_sf <- st_as_sf(storefronts,coords = c("LATITUDE","LONGITUDE"))
storefronts_sf <- st_as_sf(storefronts,coords = c("LATITUDE","LONGITUDE")) %>%
st_set_crs(crs = 2263)
storefronts_sf <- st_as_sf(storefronts,coords = c("LATITUDE","LONGITUDE"))
library(tmap)
tm_shape(storefront_sf) +
tm_dots()
storefronts_sf <- st_as_sf(storefronts,coords = c("LATITUDE","LONGITUDE"))
tm_shape(storefront_sf) +
tm_dots()
tm_shape(storefront_sf) +
tm_dots()
tm_shape(storefront_sf) +
tm_dots()
tm_shape(storefronts_sf) +
tm_dots()
tmap_mode("view")
tm_shape(storefronts_sf) +
tm_dots()
storefronts_sf <- st_as_sf(storefronts,coords = c("LONGITUDE","LATITUDE"))
tmap_mode("view")
tm_shape(storefronts_sf) +
tm_dots()
################################################################################
###   Author: Sean Chew
###   PURPOSE:
################################################################################
### Set Environment ------------------------------------------------------------
# Clear the environment
rm(list=ls())
gc()
# So the code will compile warnings as per usual
options(warn = 0)
# So that text data is not read in as factors
options(stringsAsFactors = F)
# Turn off scientific notation
options(scipen = 999)
### Load Packages --------------------------------------------------------------
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, magrittr, stringr, reshape2, janitor,
lubridate, readxl, ggplot2, scales, readr,
tidyr, zoo, skimr, openxlsx,ggspatial, rgeos,RColorBrewer,
tidyverse, rio, collapse, sf, glue, XML, tm, here, purrr, repurrrsive,
tmap,tidygraph, nabor,igraph, viridis, hrbrthemes,RSocrata,soql,ggmap,
geojsonsf)
### Begin Code -----------------------------------------------------------------
options(scipen = 100)
storefronts <- read_csv("./data/Storefronts_Reported_Vacant_or_Not.csv") %>%
filter(!is.na(LATITUDE),
!is.na(LONGITUDE),
LATITUDE > 0,
LONGITUDE < 0)
getwd()
setwd("./Documents/GitHub/data_viz/")
getwd()
################################################################################
###   Author: Sean Chew
###   PURPOSE:
################################################################################
### Set Environment ------------------------------------------------------------
# Clear the environment
rm(list=ls())
gc()
# So the code will compile warnings as per usual
options(warn = 0)
# So that text data is not read in as factors
options(stringsAsFactors = F)
################################################################################
###   Author: Sean Chew
###   PURPOSE:
################################################################################
### Set Environment ------------------------------------------------------------
# Clear the environment
rm(list=ls())
gc()
# So the code will compile warnings as per usual
options(warn = 0)
# So that text data is not read in as factors
#options(stringsAsFactors = F)
# Turn off scientific notation
options(scipen = 999)
### Load Packages --------------------------------------------------------------
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, magrittr, stringr, reshape2, janitor,
lubridate, readxl, ggplot2, scales, readr,
tidyr, zoo, skimr, openxlsx,ggspatial, rgeos,RColorBrewer,
tidyverse, rio, collapse, sf, glue, XML, tm, here, purrr, repurrrsive,
tmap,tidygraph, nabor,igraph, viridis, hrbrthemes,RSocrata,soql,ggmap,
geojsonsf)
### Begin Code -----------------------------------------------------------------
options(scipen = 100)
storefronts <- read_csv("./data/Storefronts_Reported_Vacant_or_Not.csv") %>%
filter(!is.na(LATITUDE),
!is.na(LONGITUDE),
LATITUDE > 0,
LONGITUDE < 0)
storefronts_sf <- st_as_sf(storefronts,coords = c("LONGITUDE","LATITUDE")) %>%
clean_names() %>%
st_set_crs(4326) %>% st_transform(4326)
storefronts_by_halfyear <- storefronts_sf %>%
filter(vacant_on_12_31 == "YES" | vacant_6_30_or_date_sold_if_earlier == "YES") %>%
mutate(vacant_6_30_or_date_sold_if_earlier =
ifelse(is.na(vacant_6_30_or_date_sold_if_earlier),"NO",
vacant_6_30_or_date_sold_if_earlier))
storefronts_2020_1 <- storefronts_by_halfyear %>% # 6165 units vacant
filter(vacant_on_12_31 == "YES" & reporting_year == "2019 and 2020")
# I don't think this is actually a good way to account for it.
# storefronts_2020_2 <- storefronts_by_halfyear %>% # 6165 units vacant
#     filter(vacant_6_30_or_date_sold_if_earlier == "YES" & reporting_year == "2019 and 2020")
#
storefronts_2021_1 <- storefronts_by_halfyear %>% # 7614 units vacant
filter(vacant_on_12_31 == "YES" & reporting_year == "2020 and 2021")
# storefronts_2021_2 <- storefronts_by_halfyear %>% # 6165 units vacant # 3378
#     filter(vacant_6_30_or_date_sold_if_earlier == "YES" & reporting_year == "2020 and 2021")
#write_sf(storefronts_2020_1,"./intermediate/for_heatmap/storefronts_2020.shp")
#write_sf(storefronts_2021_1,"./intermediate/for_heatmap/storefronts_2021.shp")
# geo_2020 <- sf_geojson(storefronts_2020_1)
# geo_2021 <- sf_geojson(storefronts_2021_1)
# sf::st_write(nc, dsn = "./intermediate/geo_2020.geojson", layer = "nc.geojson")
# write_sf(geo_2020, "./intermediate/geo_2020.geojson")
###
#sf::st_write(storefronts_2020_1, dsn = "./intermediate/geo_2020.geojson", layer = "geo_2020.geojson")
#sf::st_write(storefronts_2021_1, dsn = "./intermediate/geo_2021.geojson", layer = "geo_2021.geojson")
# storefronts_change <- storefronts_2021_1 %>%
#     left_join(storefronts_2020_1 %>% st_drop_geometry() %>%
#                   select(-c("reporting_year")),
#               by = c("bbl","bin","property_street_address_or_storefront_address","unit","property_street","property_number",
#                      "construction_reported","borough_block_lot"))
# ggmap(storefronts_2021_1, extent = 'device', legend = "topleft") +
#     geom_density_2d_filled(data = storefronts_2021_1, alpha = 0.3)
#### Exploratory Data Analysis
NTA <- read_sf("./data/NTA map/geo_export_32c56777-0bc5-48c7-9917-05b5a42c7b84.shp")%>%
st_transform(3857)
#sf::st_write(NTA, dsn = "./intermediate/nta.geojson", layer = "nta.geojson")
# set defaults for the basemap
# set_defaults(map_service = "carto", map_type = "dark")
# nyc_raster<-basemap_raster(storefronts_sf)
# nyc_raster
#
# tmap_mode("plot")
#
# tm_shape(nyc_raster)+
#     tm_rgb() +
#     tm_shape(storefronts_sf) +
#     tm_dots(col = "primary_business_activity") +
#     tm_facets(by = "reporting_year")
#
# ggplot(storefronts_sf %>% st_drop_geometry(),aes(x=as.factor(primary_business_activity) )) +
#     geom_bar() +
#     coord_flip() +
#     facet_grid(cols = vars(reporting_year))
storefronts_varisa <- storefronts_sf %>%
st_drop_geometry() %>%
mutate(primary_business_activity = ifelse(primary_business_activity == "HEALTH CARE or SOCIAL ASSISTANCE",
"HEALTH CARE OR SOCIAL ASSISTANCE",
primary_business_activity)) %>%
group_by(reporting_year,primary_business_activity) %>%
count()
ggplot(storefronts_varisa,aes(x=primary_business_activity,y = n)) +
geom_bar(stat ="identity") +
coord_flip() +
facet_grid(cols = vars(reporting_year))
names(storefronts_sf)
storefronts_varisa <- storefronts_sf %>%
st_drop_geometry() %>%
mutate(primary_business_activity = ifelse(primary_business_activity == "HEALTH CARE or SOCIAL ASSISTANCE",
"HEALTH CARE OR SOCIAL ASSISTANCE",
primary_business_activity)) %>%
group_by(reporting_year,primary_business_activity,borough) %>%
count()
ggplot(storefronts_varisa,aes(x=primary_business_activity,y = n)) +
geom_bar(stat ="identity") +
coord_flip() +
facet_grid(cols = vars(reporting_year))
ggplot(storefronts_varisa,aes(x=primary_business_activity,y = n)) +
geom_bar(stat ="identity") +
coord_flip() +
facet_grid(cols = vars(reporting_year,borough))
View(storefronts_varisa)
storefronts_varisa_wide <- storefronts_varisa %>%
pivot_wider(names_from = reporting_year,values_from = n)
View(storefronts_varisa_wide)
storefronts_varisa_wide <- storefronts_varisa %>%
pivot_wider(names_from = reporting_year,values_from = n) %>%
clean_names()
names(storefronts_varisa_wide)
storefronts_varisa_wide <- storefronts_varisa %>%
pivot_wider(names_from = reporting_year,values_from = n) %>%
clean_names() %>%
mutate(change = x2020_and_2021 - x2019_and_2020)
ggplot(storefronts_varisa,aes(x=primary_business_activity,y = change)) +
geom_bar(stat ="identity") +
coord_flip() +
facet_grid(cols = vars(borough))
ggplot(storefronts_varisa_wide,aes(x=primary_business_activity,y = change)) +
geom_bar(stat ="identity") +
coord_flip() +
facet_grid(cols = vars(borough))
################################################################################
###   Author: Sean Chew
###   PURPOSE:
################################################################################
### Set Environment ------------------------------------------------------------
# Clear the environment
rm(list=ls())
gc()
# So the code will compile warnings as per usual
options(warn = 0)
# So that text data is not read in as factors
#options(stringsAsFactors = F)
# Turn off scientific notation
options(scipen = 999)
### Load Packages --------------------------------------------------------------
if(!require("pacman")) install.packages("pacman")
pacman::p_load(dplyr, magrittr, stringr, reshape2, janitor,
lubridate, readxl, ggplot2, scales, readr,
tidyr, zoo, skimr, openxlsx,ggspatial, rgeos,RColorBrewer,
tidyverse, rio, collapse, sf, glue, XML, tm, here, purrr, repurrrsive,
tmap,tidygraph, nabor,igraph, viridis, hrbrthemes,RSocrata,soql,ggmap,
geojsonsf)
### Begin Code -----------------------------------------------------------------
options(scipen = 100)
storefronts <- read_csv("./data/Storefronts_Reported_Vacant_or_Not.csv") %>%
filter(!is.na(LATITUDE),
!is.na(LONGITUDE),
LATITUDE > 0,
LONGITUDE < 0)
storefronts <- read_csv("./data/storefront_MapPluto_NTA.csv")
View(storefronts)
hist(storefronts)
hist(storefronts$NO_count)
View(storefronts)
